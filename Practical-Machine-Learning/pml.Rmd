---
title: "Practical Machine Learning Project"
author: "John J. Como, MD, MPH"
date: "October 25, 2015"
output: pdf_document
---

Background


Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. 

In this project, my goal was to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. 

More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset). 
------------------------------------------------------------------------------------------------------------------------------------------------------

Data

The training data for this project were available here: 

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data were available here: 

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

Both of these files were downloaded into the working directory, generating the two files:
1)  pml-training.csv
2)  pml-testing.csv

The data for this project came from this source: http://groupware.les.inf.puc-rio.br/har.
------------------------------------------------------------------------------------------------------------------------------------------------------

First, I read in the training and the testing data from the respective csv files.  I changed all missing data to type "NA".
```{r}
training<-read.csv("pml-training.csv", na.strings=c("#DIV/0!", "", "NA"))
testing<-read.csv("pml-testing.csv", na.strings=c("#DIV/0!", "", "NA"))
dim(training)
dim(testing)
```
You can see that the original training file has 19622 obervations and the testing file has 20 observations.  Both originally have 160 variables.

The relevant data are located in columns 8 through 159.  The 160th column of the training data contains the outcome variable "classe".  The 160th column of the 20 test cases contained the values 1 through 20, and it was deleted.  Also, columns with overwhelminly missing data were also deleted - see variable "omit" below.
```{r}
training<-training[, 8:160]
testing<-testing[, 8:160]
omit<-which(colSums(is.na(training))>19200)
training<-training[, -omit]
testing<-testing[, -omit]
testing<-testing[, -dim(testing)[2]]
dim(training)
dim(testing)
```
Now the training file has 53 variables (includes the dependent variable "classe"), and the testing file has 52.

In cross-validation, we use the training set, we split it into training/test sets, we build a model on the training set, and we evaluate this model on the test set.

Three-fourths of the data is set to be training data ("train"), and one-fourth is testing data ("test").  This latter "test" data, which contains 4904 observations, is not to be confused with the 20 test cases referred to above.  The "train" data contains 14718 observations.

The seed is set for reproducibility.
```{r}
set.seed(125)
library(caret)
inTrain<-createDataPartition(training$classe, p=3/4, list=FALSE)
train<-training[inTrain,]
test<-training[-inTrain,]
```

A random forest predictor was fit relating the variable "classe" to the remaining variables in the training set.  A confusion matrix was generated.
```{r}
library(randomForest)
modFit<-randomForest(classe~., data=train, ntree=500)
modFit
```
The OOB (out of bag) error estimate is very low at 0.53%.  This indicates that the prediction model is accurate on the training set.

The random forest predictor was then used on the "test" data (4904 variables).  Another confusion matrix was generated.  We do not expect this error to be as small as the error on the training set.
```{r}
predRF<-predict(modFit, test)
confusionMatrix(predRF, test$classe)
```
The out of sample error is the error you get on a new data set.  This will always be greater than in sample error.  The accuracy of the model is 0.993, indicating that the prediction model is also very accurate on the testing set.

------------------------------------------------------------------------------------------------------------------------------------------------------

The algorithm was then applied to the 20 test cases.  Files containing the predictions are written to the working directory.
```{r}
predictionAssignment<-as.character(predict(modFit, testing))

pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

predictionAssignment
pml_write_files(predictionAssignment)
```
